{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load(r'C:\\Project\\Bird_drone_CWT\\RPC12_Input_For_Participants\\datasets\\data_SAAB_SIRS_77GHz_FMCW.npy', allow_pickle=True)\n",
    "\n",
    "# Extract relevant data: complex-valued data matrix from Column 2\n",
    "complex_data = data[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1228)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = data[0]\n",
    "complex_valued_data = first_row[1]\n",
    "complex_valued_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ensure complex_valued_data is a numpy array\n",
    "complex_valued_data = np.array(complex_valued_data, dtype=np.complex128)\n",
    "\n",
    "# Separate real and imaginary parts\n",
    "real_part = np.real(complex_valued_data)\n",
    "imaginary_part = np.imag(complex_valued_data)\n",
    "\n",
    "# Combine real and imaginary parts into a 2D array\n",
    "combined_data = np.column_stack((real_part, imaginary_part))\n",
    "\n",
    "# Save to a text file\n",
    "np.savetxt('complex_data.txt', combined_data, fmt='%.6f', header='Real Part, Imaginary Part')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scalogram image for segment 1/130...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhars\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pywt\\_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scalogram image for segment 2/130...\n",
      "Saving scalogram image for segment 3/130...\n",
      "Saving scalogram image for segment 4/130...\n",
      "Saving scalogram image for segment 5/130...\n",
      "Saving scalogram image for segment 6/130...\n",
      "Saving scalogram image for segment 7/130...\n",
      "Saving scalogram image for segment 8/130...\n",
      "Saving scalogram image for segment 9/130...\n",
      "Saving scalogram image for segment 10/130...\n",
      "Saving scalogram image for segment 11/130...\n",
      "Saving scalogram image for segment 12/130...\n",
      "Saving scalogram image for segment 13/130...\n",
      "Saving scalogram image for segment 14/130...\n",
      "Saving scalogram image for segment 15/130...\n",
      "Saving scalogram image for segment 16/130...\n",
      "Saving scalogram image for segment 17/130...\n",
      "Saving scalogram image for segment 18/130...\n",
      "Saving scalogram image for segment 19/130...\n",
      "Saving scalogram image for segment 20/130...\n",
      "Saving scalogram image for segment 21/130...\n",
      "Saving scalogram image for segment 22/130...\n",
      "Saving scalogram image for segment 23/130...\n",
      "Saving scalogram image for segment 24/130...\n",
      "Saving scalogram image for segment 25/130...\n",
      "Saving scalogram image for segment 26/130...\n",
      "Saving scalogram image for segment 27/130...\n",
      "Saving scalogram image for segment 28/130...\n",
      "Saving scalogram image for segment 29/130...\n",
      "Saving scalogram image for segment 30/130...\n",
      "Saving scalogram image for segment 31/130...\n",
      "Saving scalogram image for segment 32/130...\n",
      "Saving scalogram image for segment 33/130...\n",
      "Saving scalogram image for segment 34/130...\n",
      "Saving scalogram image for segment 35/130...\n",
      "Saving scalogram image for segment 36/130...\n",
      "Saving scalogram image for segment 37/130...\n",
      "Saving scalogram image for segment 38/130...\n",
      "Saving scalogram image for segment 39/130...\n",
      "Saving scalogram image for segment 40/130...\n",
      "Saving scalogram image for segment 41/130...\n",
      "Saving scalogram image for segment 42/130...\n",
      "Saving scalogram image for segment 43/130...\n",
      "Saving scalogram image for segment 44/130...\n",
      "Saving scalogram image for segment 45/130...\n",
      "Saving scalogram image for segment 46/130...\n",
      "Saving scalogram image for segment 47/130...\n",
      "Saving scalogram image for segment 48/130...\n",
      "Saving scalogram image for segment 49/130...\n",
      "Saving scalogram image for segment 50/130...\n",
      "Saving scalogram image for segment 51/130...\n",
      "Saving scalogram image for segment 52/130...\n",
      "Saving scalogram image for segment 53/130...\n",
      "Saving scalogram image for segment 54/130...\n",
      "Saving scalogram image for segment 55/130...\n",
      "Saving scalogram image for segment 56/130...\n",
      "Saving scalogram image for segment 57/130...\n",
      "Saving scalogram image for segment 58/130...\n",
      "Saving scalogram image for segment 59/130...\n",
      "Saving scalogram image for segment 60/130...\n",
      "Saving scalogram image for segment 61/130...\n",
      "Saving scalogram image for segment 62/130...\n",
      "Saving scalogram image for segment 63/130...\n",
      "Saving scalogram image for segment 64/130...\n",
      "Saving scalogram image for segment 65/130...\n",
      "Saving scalogram image for segment 66/130...\n",
      "Saving scalogram image for segment 67/130...\n",
      "Saving scalogram image for segment 68/130...\n",
      "Saving scalogram image for segment 69/130...\n",
      "Saving scalogram image for segment 70/130...\n",
      "Saving scalogram image for segment 71/130...\n",
      "Saving scalogram image for segment 72/130...\n",
      "Saving scalogram image for segment 73/130...\n",
      "Saving scalogram image for segment 74/130...\n",
      "Saving scalogram image for segment 75/130...\n",
      "Saving scalogram image for segment 76/130...\n",
      "Saving scalogram image for segment 77/130...\n",
      "Saving scalogram image for segment 78/130...\n",
      "Saving scalogram image for segment 79/130...\n",
      "Saving scalogram image for segment 80/130...\n",
      "Saving scalogram image for segment 81/130...\n",
      "Saving scalogram image for segment 82/130...\n",
      "Saving scalogram image for segment 83/130...\n",
      "Saving scalogram image for segment 84/130...\n",
      "Saving scalogram image for segment 85/130...\n",
      "Saving scalogram image for segment 86/130...\n",
      "Saving scalogram image for segment 87/130...\n",
      "Saving scalogram image for segment 88/130...\n",
      "Saving scalogram image for segment 89/130...\n",
      "Saving scalogram image for segment 90/130...\n",
      "Saving scalogram image for segment 91/130...\n",
      "Saving scalogram image for segment 92/130...\n",
      "Saving scalogram image for segment 93/130...\n",
      "Saving scalogram image for segment 94/130...\n",
      "Saving scalogram image for segment 95/130...\n",
      "Saving scalogram image for segment 96/130...\n",
      "Saving scalogram image for segment 97/130...\n",
      "Saving scalogram image for segment 98/130...\n",
      "Saving scalogram image for segment 99/130...\n",
      "Saving scalogram image for segment 100/130...\n",
      "Saving scalogram image for segment 101/130...\n",
      "Saving scalogram image for segment 102/130...\n",
      "Saving scalogram image for segment 103/130...\n",
      "Saving scalogram image for segment 104/130...\n",
      "Saving scalogram image for segment 105/130...\n",
      "Saving scalogram image for segment 106/130...\n",
      "Saving scalogram image for segment 107/130...\n",
      "Saving scalogram image for segment 108/130...\n",
      "Saving scalogram image for segment 109/130...\n",
      "Saving scalogram image for segment 110/130...\n",
      "Saving scalogram image for segment 111/130...\n",
      "Saving scalogram image for segment 112/130...\n",
      "Saving scalogram image for segment 113/130...\n",
      "Saving scalogram image for segment 114/130...\n",
      "Saving scalogram image for segment 115/130...\n",
      "Saving scalogram image for segment 116/130...\n",
      "Saving scalogram image for segment 117/130...\n",
      "Saving scalogram image for segment 118/130...\n",
      "Saving scalogram image for segment 119/130...\n",
      "Saving scalogram image for segment 120/130...\n",
      "Saving scalogram image for segment 121/130...\n",
      "Saving scalogram image for segment 122/130...\n",
      "Saving scalogram image for segment 123/130...\n",
      "Saving scalogram image for segment 124/130...\n",
      "Saving scalogram image for segment 125/130...\n",
      "Saving scalogram image for segment 126/130...\n",
      "Saving scalogram image for segment 127/130...\n",
      "Saving scalogram image for segment 128/130...\n",
      "Saving scalogram image for segment 129/130...\n",
      "Saving scalogram image for segment 130/130...\n",
      "Extracting features from image 1/130...\n",
      "Extracting features from image 2/130...\n",
      "Extracting features from image 3/130...\n",
      "Extracting features from image 4/130...\n",
      "Extracting features from image 5/130...\n",
      "Extracting features from image 6/130...\n",
      "Extracting features from image 7/130...\n",
      "Extracting features from image 8/130...\n",
      "Extracting features from image 9/130...\n",
      "Extracting features from image 10/130...\n",
      "Extracting features from image 11/130...\n",
      "Extracting features from image 12/130...\n",
      "Extracting features from image 13/130...\n",
      "Extracting features from image 14/130...\n",
      "Extracting features from image 15/130...\n",
      "Extracting features from image 16/130...\n",
      "Extracting features from image 17/130...\n",
      "Extracting features from image 18/130...\n",
      "Extracting features from image 19/130...\n",
      "Extracting features from image 20/130...\n",
      "Extracting features from image 21/130...\n",
      "Extracting features from image 22/130...\n",
      "Extracting features from image 23/130...\n",
      "Extracting features from image 24/130...\n",
      "Extracting features from image 25/130...\n",
      "Extracting features from image 26/130...\n",
      "Extracting features from image 27/130...\n",
      "Extracting features from image 28/130...\n",
      "Extracting features from image 29/130...\n",
      "Extracting features from image 30/130...\n",
      "Extracting features from image 31/130...\n",
      "Extracting features from image 32/130...\n",
      "Extracting features from image 33/130...\n",
      "Extracting features from image 34/130...\n",
      "Extracting features from image 35/130...\n",
      "Extracting features from image 36/130...\n",
      "Extracting features from image 37/130...\n",
      "Extracting features from image 38/130...\n",
      "Extracting features from image 39/130...\n",
      "Extracting features from image 40/130...\n",
      "Extracting features from image 41/130...\n",
      "Extracting features from image 42/130...\n",
      "Extracting features from image 43/130...\n",
      "Extracting features from image 44/130...\n",
      "Extracting features from image 45/130...\n",
      "Extracting features from image 46/130...\n",
      "Extracting features from image 47/130...\n",
      "Extracting features from image 48/130...\n",
      "Extracting features from image 49/130...\n",
      "Extracting features from image 50/130...\n",
      "Extracting features from image 51/130...\n",
      "Extracting features from image 52/130...\n",
      "Extracting features from image 53/130...\n",
      "Extracting features from image 54/130...\n",
      "Extracting features from image 55/130...\n",
      "Extracting features from image 56/130...\n",
      "Extracting features from image 57/130...\n",
      "Extracting features from image 58/130...\n",
      "Extracting features from image 59/130...\n",
      "Extracting features from image 60/130...\n",
      "Extracting features from image 61/130...\n",
      "Extracting features from image 62/130...\n",
      "Extracting features from image 63/130...\n",
      "Extracting features from image 64/130...\n",
      "Extracting features from image 65/130...\n",
      "Extracting features from image 66/130...\n",
      "Extracting features from image 67/130...\n",
      "Extracting features from image 68/130...\n",
      "Extracting features from image 69/130...\n",
      "Extracting features from image 70/130...\n",
      "Extracting features from image 71/130...\n",
      "Extracting features from image 72/130...\n",
      "Extracting features from image 73/130...\n",
      "Extracting features from image 74/130...\n",
      "Extracting features from image 75/130...\n",
      "Extracting features from image 76/130...\n",
      "Extracting features from image 77/130...\n",
      "Extracting features from image 78/130...\n",
      "Extracting features from image 79/130...\n",
      "Extracting features from image 80/130...\n",
      "Extracting features from image 81/130...\n",
      "Extracting features from image 82/130...\n",
      "Extracting features from image 83/130...\n",
      "Extracting features from image 84/130...\n",
      "Extracting features from image 85/130...\n",
      "Extracting features from image 86/130...\n",
      "Extracting features from image 87/130...\n",
      "Extracting features from image 88/130...\n",
      "Extracting features from image 89/130...\n",
      "Extracting features from image 90/130...\n",
      "Extracting features from image 91/130...\n",
      "Extracting features from image 92/130...\n",
      "Extracting features from image 93/130...\n",
      "Extracting features from image 94/130...\n",
      "Extracting features from image 95/130...\n",
      "Extracting features from image 96/130...\n",
      "Extracting features from image 97/130...\n",
      "Extracting features from image 98/130...\n",
      "Extracting features from image 99/130...\n",
      "Extracting features from image 100/130...\n",
      "Extracting features from image 101/130...\n",
      "Extracting features from image 102/130...\n",
      "Extracting features from image 103/130...\n",
      "Extracting features from image 104/130...\n",
      "Extracting features from image 105/130...\n",
      "Extracting features from image 106/130...\n",
      "Extracting features from image 107/130...\n",
      "Extracting features from image 108/130...\n",
      "Extracting features from image 109/130...\n",
      "Extracting features from image 110/130...\n",
      "Extracting features from image 111/130...\n",
      "Extracting features from image 112/130...\n",
      "Extracting features from image 113/130...\n",
      "Extracting features from image 114/130...\n",
      "Extracting features from image 115/130...\n",
      "Extracting features from image 116/130...\n",
      "Extracting features from image 117/130...\n",
      "Extracting features from image 118/130...\n",
      "Extracting features from image 119/130...\n",
      "Extracting features from image 120/130...\n",
      "Extracting features from image 121/130...\n",
      "Extracting features from image 122/130...\n",
      "Extracting features from image 123/130...\n",
      "Extracting features from image 124/130...\n",
      "Extracting features from image 125/130...\n",
      "Extracting features from image 126/130...\n",
      "Extracting features from image 127/130...\n",
      "Extracting features from image 128/130...\n",
      "Extracting features from image 129/130...\n",
      "Extracting features from image 130/130...\n",
      "Features from the first image: {'frequency_peaks': 39, 'avg_peak_height': 0.7497979512317747, 'periodicity': 16.952107869490348, 'modulation_variance': 0.06970923415639042}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.signal import find_peaks\n",
    "import cv2\n",
    "import os\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Define directories for saving and loading images\n",
    "save_dir = 'scalogram_images'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "\n",
    "# Extract the complex-valued radar signal data (Column 2)\n",
    "complex_data = data[:, 1]\n",
    "\n",
    "# Define CWT parameters\n",
    "wavelet = 'cmor'  # Complex Morlet wavelet\n",
    "scales = np.arange(1, 128)  # Reduce scale range to save memory\n",
    "fs = 17000  # Original sampling frequency (radar PRF)\n",
    "downsample_factor = 4  # Factor to downsample by\n",
    "\n",
    "# Function to perform CWT and save scalogram images\n",
    "def save_scalogram_image(segment, index):\n",
    "    # Downsample the signal to reduce memory usage\n",
    "    segment_downsampled = resample(segment.flatten(), len(segment) // downsample_factor)\n",
    "    \n",
    "    # Perform CWT on downsampled signal\n",
    "    coef, _ = pywt.cwt(segment_downsampled, scales, wavelet)\n",
    "    \n",
    "    # Absolute values for magnitude representation\n",
    "    scalogram = np.abs(coef)\n",
    "    \n",
    "    # Save scalogram as image\n",
    "    plt.imshow(scalogram, aspect='auto', cmap='jet', origin='lower')\n",
    "    plt.colorbar()\n",
    "    plt.title(f'Scalogram - Segment {index + 1}')\n",
    "    plt.savefig(os.path.join(save_dir, f'scalogram_{index + 1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Save all scalograms as images\n",
    "for i, segment in enumerate(complex_data):\n",
    "    print(f'Saving scalogram image for segment {i + 1}/{len(complex_data)}...')\n",
    "    save_scalogram_image(segment, i)\n",
    "\n",
    "# Function to extract features from scalogram images\n",
    "def extract_features_from_image(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # If image loading fails, return default features\n",
    "    if img is None:\n",
    "        return {\n",
    "            'frequency_peaks': 0,\n",
    "            'avg_peak_height': 0,\n",
    "            'periodicity': 0,\n",
    "            'modulation_variance': 0,\n",
    "        }\n",
    "    \n",
    "    # Convert image to float and normalize\n",
    "    img = img.astype(float)\n",
    "    img /= np.max(img)\n",
    "    \n",
    "    # Compute features from the image\n",
    "    avg_frequency_magnitude = np.mean(img, axis=1)\n",
    "    peaks, _ = find_peaks(avg_frequency_magnitude, height=np.max(avg_frequency_magnitude) * 0.5)\n",
    "    \n",
    "    peak_intervals = np.diff(peaks)  # Differences between peak indices\n",
    "    periodicity = np.std(peak_intervals) if len(peak_intervals) > 1 else 0\n",
    "\n",
    "    modulation_pattern = np.var(img, axis=1)\n",
    "\n",
    "    features = {\n",
    "        'frequency_peaks': len(peaks),\n",
    "        'avg_peak_height': np.mean(avg_frequency_magnitude[peaks]) if peaks.size > 0 else 0,\n",
    "        'periodicity': periodicity,\n",
    "        'modulation_variance': np.mean(modulation_pattern),\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# Extract features from all scalogram images\n",
    "all_features = []\n",
    "for i in range(len(complex_data)):\n",
    "    image_path = os.path.join(save_dir, f'scalogram_{i + 1}.png')\n",
    "    print(f'Extracting features from image {i + 1}/{len(complex_data)}...')\n",
    "    features = extract_features_from_image(image_path)\n",
    "    all_features.append(features)\n",
    "\n",
    "# Example: Print features of the first segment\n",
    "print(\"Features from the first image:\", all_features[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset: ['CR' 'D1' 'D2' 'D3' 'D4' 'D5' 'D6' 'black-headed gull' 'heron'\n",
      " 'human_run' 'human_walk' 'pigeon' 'raven' 'seagull'\n",
      " 'seagull and black-headed gull']\n",
      "Unique labels after mapping: ['bird' 'drone' 'human']\n",
      "Number of valid samples: 111\n",
      "   frequency_peaks  avg_peak_height  periodicity  modulation_variance  label\n",
      "0               39         0.749798    16.952108             0.069709  drone\n",
      "1               43         0.784036    12.635300             0.062910  drone\n",
      "2               50         0.729242     9.593791             0.075981  drone\n",
      "3               60         0.806211     9.556407             0.055883  drone\n",
      "4               54         0.725570    11.925782             0.089771  drone\n",
      "Feature matrix shape: (111, 4)\n",
      "Labels shape: (111,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Extract labels from Column 1\n",
    "labels = data[:, 0]\n",
    "\n",
    "# Ensure labels are plain strings by accessing the first element in each array\n",
    "labels = [str(label[0]) if isinstance(label, (list, np.ndarray)) else str(label) for label in labels]\n",
    "\n",
    "# Print unique labels in the dataset\n",
    "print(\"Unique labels in the dataset:\", np.unique(labels))\n",
    "\n",
    "# Create a new mapping for simplified classification\n",
    "simplified_label_mapping = {\n",
    "    'D1': 'drone', 'D2': 'drone', 'D3': 'drone', 'D4': 'drone', \n",
    "    'D5': 'drone', 'D6': 'drone',  # All drone types\n",
    "    'human_walk': 'human', 'human_run': 'human',  # Human activities\n",
    "    'seagull': 'bird', 'pigeon': 'bird', 'raven': 'bird', 'black-headed gull': 'bird',\n",
    "    'seagull and black-headed gull': 'bird', 'heron': 'bird',  # All bird types\n",
    "    'CR': None  # Ignore corner reflector samples or map them to a category if needed\n",
    "}\n",
    "\n",
    "# Apply the simplified label mapping\n",
    "simplified_labels = np.array([simplified_label_mapping.get(label, None) for label in labels])\n",
    "\n",
    "# Print unique labels after mapping\n",
    "print(\"Unique labels after mapping:\", np.unique([label for label in simplified_labels if label is not None]))\n",
    "\n",
    "# Remove rows with 'None' labels (corner reflector or any unwanted data)\n",
    "valid_indices = [i for i, label in enumerate(simplified_labels) if label is not None]\n",
    "simplified_features = [all_features[i] for i in valid_indices]\n",
    "\n",
    "# Check if we have valid data after filtering\n",
    "print(f\"Number of valid samples: {len(valid_indices)}\")\n",
    "\n",
    "if len(valid_indices) == 0:\n",
    "    print(\"No valid data found after filtering. Check the label mapping or data extraction.\")\n",
    "else:\n",
    "    # Convert the list of features to a pandas DataFrame\n",
    "    features_df = pd.DataFrame(simplified_features)\n",
    "\n",
    "    # Add the simplified labels as a new column\n",
    "    features_df['label'] = simplified_labels[valid_indices]\n",
    "\n",
    "    # Display the first few rows to check the combined DataFrame\n",
    "    print(features_df.head())\n",
    "\n",
    "    # Convert the DataFrame to a NumPy array (if needed for certain ML libraries)\n",
    "    features_array = features_df.to_numpy()\n",
    "\n",
    "    # Separate features (X) and labels (y)\n",
    "    X = features_array[:, :-1]  # All columns except the last\n",
    "    y = features_array[:, -1]   # The last column (simplified label)\n",
    "\n",
    "    # Display the shapes of X and y to confirm\n",
    "    print(\"Feature matrix shape:\", X.shape)\n",
    "    print(\"Labels shape:\", y.shape)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, skew, kurtosis\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(signal):\n",
    "    # Calculate entropy, skewness, and kurtosis\n",
    "    signal_entropy = entropy(np.abs(signal) + 1e-10)  # Adding small value to avoid log(0) issue in entropy\n",
    "    signal_skewness = skew(np.abs(signal))\n",
    "    signal_kurtosis = kurtosis(np.abs(signal))\n",
    "\n",
    "    # Calculate band power (example for a specific frequency band)\n",
    "    band_power = np.sum(np.abs(signal)**2)\n",
    "\n",
    "    # Ensure all extracted features are scalar values\n",
    "    return [signal_entropy, signal_skewness, signal_kurtosis, band_power]\n",
    "\n",
    "# Apply feature extraction to all segments\n",
    "features = [extract_features(segment.flatten()) for segment in complex_data]\n",
    "\n",
    "# Convert to numpy array after ensuring all elements are consistent in length\n",
    "X_new_features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_old: (111, 4)\n",
      "Shape of X_new_features: (130, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of both arrays\n",
    "print(f\"Shape of X_old: {X.shape}\")\n",
    "print(f\"Shape of X_new_features: {X_new_features.shape}\")\n",
    "\n",
    "# Trim or align data\n",
    "if X.shape[0] < X_new_features.shape[0]:\n",
    "    X_new_features = X_new_features[:X.shape[0], :]\n",
    "elif X.shape[0] > X_new_features.shape[0]:\n",
    "    X_old = X[:X_new_features.shape[0], :]\n",
    "\n",
    "# Horizontally stack the features after ensuring they have the same number of rows\n",
    "X_combined = np.hstack((X, X_new_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Example: Assuming 'X' is your feature matrix\n",
    "scaler = StandardScaler()  # Use MinMaxScaler() for normalization\n",
    "X_scaled = scaler.fit_transform(X_combined)  # Normalizing/Standardizing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Assuming X_scaled is your feature matrix and y is your target vector\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drone'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 1.1699 - val_loss: 1.2433\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2007 - val_loss: 1.2087\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1851 - val_loss: 1.1564\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1430 - val_loss: 1.0841\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0416 - val_loss: 1.0031\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9533 - val_loss: 0.9321\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8583 - val_loss: 0.8763\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7952 - val_loss: 0.8283\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7962 - val_loss: 0.7904\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7442 - val_loss: 0.7692\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6914 - val_loss: 0.7566\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6409 - val_loss: 0.7484\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6666 - val_loss: 0.7362\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6680 - val_loss: 0.7268\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6563 - val_loss: 0.7183\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.6241 - val_loss: 0.7080\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6851 - val_loss: 0.6949\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6185 - val_loss: 0.6777\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.6155 - val_loss: 0.6496\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.6109 - val_loss: 0.6204\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5948 - val_loss: 0.6005\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5834 - val_loss: 0.5954\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5573 - val_loss: 0.5925\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5873 - val_loss: 0.5846\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5897 - val_loss: 0.5815\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5595 - val_loss: 0.5804\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5688 - val_loss: 0.5799\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5820 - val_loss: 0.5773\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5814 - val_loss: 0.5757\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5668 - val_loss: 0.5755\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5672 - val_loss: 0.5749\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5511 - val_loss: 0.5744\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5357 - val_loss: 0.5737\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5584 - val_loss: 0.5736\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5434 - val_loss: 0.5737\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5318 - val_loss: 0.5730\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5635 - val_loss: 0.5732\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5675 - val_loss: 0.5738\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5689 - val_loss: 0.5729\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5726 - val_loss: 0.5725\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5662 - val_loss: 0.5727\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5198 - val_loss: 0.5721\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5643 - val_loss: 0.5725\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5556 - val_loss: 0.5720\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.5530 - val_loss: 0.5734\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5744 - val_loss: 0.5731\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5598 - val_loss: 0.5722\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5607 - val_loss: 0.5720\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6046 - val_loss: 0.5732\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.5513 - val_loss: 0.5729\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Accuracy: 0.8823529411764706\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        bird       0.80      1.00      0.89        12\n",
      "       drone       1.00      0.69      0.82        13\n",
      "       human       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           0.88        34\n",
      "   macro avg       0.90      0.90      0.88        34\n",
      "weighted avg       0.90      0.88      0.88        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Autoencoder Definition\n",
    "def build_autoencoder(input_dim):\n",
    "    # Define Encoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(128, activation='relu')(input_layer)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    \n",
    "    # Define Decoder\n",
    "    decoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    \n",
    "    # Build Autoencoder\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "    \n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder, encoder\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Build and train autoencoder\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "autoencoder, encoder = build_autoencoder(input_dim)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train_scaled, X_train_scaled, epochs=50, batch_size=32, shuffle=True, validation_split=0.2)\n",
    "\n",
    "# Encode the data\n",
    "X_train_encoded = encoder.predict(X_train_scaled)\n",
    "X_test_encoded = encoder.predict(X_test_scaled)\n",
    "\n",
    "# Function for Bayesian Optimization of SVM\n",
    "def bayesian_optimization_svm(X, y):\n",
    "    # SVM Model\n",
    "    svm = SVC()\n",
    "\n",
    "    # Define parameter search space\n",
    "    param_space = {\n",
    "        'C': (1e-6, 1e+2, 'log-uniform'),  # Regularization parameter\n",
    "        'gamma': (1e-6, 1e+1, 'log-uniform'),  # Kernel coefficient\n",
    "        'kernel': ['rbf']  # Using RBF kernel\n",
    "    }\n",
    "\n",
    "    # Bayesian Search with cross-validation\n",
    "    search = BayesSearchCV(svm, param_space, n_iter=32, cv=5, random_state=42, n_jobs=-1)\n",
    "    search.fit(X, y)\n",
    "\n",
    "    return search\n",
    "\n",
    "# Perform Bayesian Optimization for SVM\n",
    "search = bayesian_optimization_svm(X_train_encoded, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = search.predict(X_test_encoded)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the autoencoder model\n",
    "autoencoder.save('autoencoder_model.h5')\n",
    "\n",
    "# Save the encoder part separately if needed\n",
    "encoder.save('encoder_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the SVM model after Bayesian Optimization\n",
    "joblib.dump(search, 'svm_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     frequency_peaks  avg_peak_height  periodicity  modulation_variance  label\n",
      "11                55         0.741952     8.974740             0.071427  drone\n",
      "12                40         0.759279    20.557260             0.083368  drone\n",
      "13                44         0.732383    12.985327             0.079751  drone\n",
      "14                55         0.733543    11.245972             0.082059  drone\n",
      "15                54         0.797218    15.445514             0.072113  drone\n",
      "..               ...              ...          ...                  ...    ...\n",
      "106               19         0.700121    49.645658             0.126285   bird\n",
      "107               55         0.610741     5.603374             0.108210   bird\n",
      "108               17         0.725300    32.618773             0.125654   bird\n",
      "109               76         0.651357     3.362909             0.093119   bird\n",
      "110               16         0.757716    66.485554             0.132315   bird\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(features_df.tail(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: bird, Count: 56\n",
      "Label: drone, Count: 44\n",
      "Label: human, Count: 11\n"
     ]
    }
   ],
   "source": [
    "unique_labels, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print results\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Label: {label}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39, 0.7497979512317747, 16.952107869490348, 0.06970923415639042,\n",
       "       13.47753931266451, 4.501689334353405, 30.485283292779023,\n",
       "       7659506.093375225], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = X_combined[0]\n",
    "\n",
    "first_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhars\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pywt\\_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Load your new radar complex-valued data\n",
    "# Assuming `new_complex_data` is a numpy array containing complex radar signals\n",
    "new_complex_data = complex_data[0]  # Load your new radar complex-valued signal here\n",
    "\n",
    "# Define CWT parameters\n",
    "wavelet = 'cmor'\n",
    "scales = np.arange(1, 128)\n",
    "downsample_factor = 4\n",
    "\n",
    "# Function to perform CWT and save scalogram images (can skip saving if not needed)\n",
    "def preprocess_radar_data(segment):\n",
    "    # Downsample the signal\n",
    "    segment_downsampled = resample(segment.flatten(), len(segment) // downsample_factor)\n",
    "    \n",
    "    # Perform CWT\n",
    "    coef, _ = pywt.cwt(segment_downsampled, scales, wavelet)\n",
    "    \n",
    "    # Absolute value for magnitude representation (scalogram)\n",
    "    scalogram = np.abs(coef)\n",
    "    \n",
    "    return scalogram\n",
    "\n",
    "# Extract scalogram features from new radar data\n",
    "def extract_features_from_scalogram(scalogram):\n",
    "    # Example feature extraction from scalogram (you can customize this)\n",
    "    avg_frequency_magnitude = np.mean(scalogram, axis=1)\n",
    "    peaks, _ = find_peaks(avg_frequency_magnitude, height=np.max(avg_frequency_magnitude) * 0.5)\n",
    "    \n",
    "    peak_intervals = np.diff(peaks)\n",
    "    periodicity = np.std(peak_intervals) if len(peak_intervals) > 1 else 0\n",
    "    modulation_pattern = np.var(scalogram, axis=1)\n",
    "    \n",
    "    features = [\n",
    "        len(peaks),\n",
    "        np.mean(avg_frequency_magnitude[peaks]) if peaks.size > 0 else 0,\n",
    "        periodicity,\n",
    "        np.mean(modulation_pattern),\n",
    "    ]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Preprocess each new radar segment\n",
    "new_features = []\n",
    "for segment in new_complex_data:\n",
    "    scalogram = preprocess_radar_data(segment)\n",
    "    features = extract_features_from_scalogram(scalogram)\n",
    "    new_features.append(features)\n",
    "\n",
    "# Convert to numpy array\n",
    "new_features = np.array(new_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to 'scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Assuming X_train is your training feature matrix\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to your training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Save the scaler to a file\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Scaler saved to 'scaler.pkl'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
